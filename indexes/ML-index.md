# MACHINE LEARNING INDEX

### A

### B

**Backpropagation**: is a technique used in neural networks to update the weights of the connections between neurons, based on the error between the predicted output and the actual output.

### C

**Cross Validation**: is a technique for evaluating ML models by training several ML models on subsets of the avilable input data and evaluating them on the complementary subset of data.

### D


**Deep learning**: is an approach to machine learning characterized by deep stacks of computations.


**Dropout**: refers to the practice of disregarding certain nodes in a layer at random during training.

### E

**Entropy**: measure of uncertainity. least entropy is when all the probability mass is in one outcome and maximal entropy is when the probability mass is uniformly distributed

### F

**Kernel**: refers to a function that calculates the similarity between pairs of data points in a dataset.

### G

### H

### J

### K

### L


**Loss function**: This measures how accurate the model is during training.

### M


**Machine Learning**: is a subset of AI that learns to make decisions by fitting mathematical models to obervsed data.

### N


**N-gram**: is a collection of n successive items in a text document that may include words, numbers, symbols, and punctuation.

### O


**Overfitting**: capturing spurious patterns that won't recur in the future, leading to less accurate predictions.

### P

### Q

### R

### S

### T

**Tensors**: a tensor is a mathematical object that can represent multi-dimensional arrays of data.

### U


**Underfitting**: failing to capture relevant patterns, again leading to less accurate predictions.

### V

### W

### X

### Y


### Z