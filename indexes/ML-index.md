# MACHINE LEARNING INDEX


**Backpropagation**: is a technique used in neural networks to update the weights of the connections between neurons, based on the error between the predicted output and the actual output.

**Cross Validation**: is a technique for evaluating ML models by training several ML models on subsets of the avilable input data and evaluating them on the complementary subset of data.


**Deep learning**: is an approach to machine learning characterized by deep stacks of computations.


**Dropout**: refers to the practice of disregarding certain nodes in a layer at random during training.

**Entropy**: measure of uncertainity. least entropy is when all the probability mass is in one outcome and maximal entropy is when the probability mass is uniformly distributed



**Kernel**: refers to a function that calculates the similarity between pairs of data points in a dataset.


**Loss function**: This measures how accurate the model is during training.


**Machine Learning**: is a subset of AI that learns to make decisions by fitting mathematical models to obersed data.


**Overfitting**: capturing spurious patterns that won't recur in the future, leading to less accurate predictions.


**Tensors**: a tensor is a mathematical object that can represent multi-dimensional arrays of data.


**Underfitting**: failing to capture relevant patterns, again leading to less accurate predictions.